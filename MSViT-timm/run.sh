python -m torch.distributed.run --nproc_per_node=8 main.py --epochs 300 --batch_size 128 --lr 2.0e-3 --model_ema true --model_ema_eval true --use_amp true --data_path /dev/shm/imagenet --output_dir ./checkpoint_1.3G --model tiny --mixup 0.2 --cutmix 0.3 | tee -a log_1.3G.txt
# python -m torch.distributed.run --nproc_per_node=8 main.py --epochs 300 --batch_size 128 --lr 2.0e-3 --model_ema true --model_ema_eval true --use_amp true --data_path /dev/shm/imagenet --output_dir ./checkpoint_2.6G --model small --mixup 0.4 --cutmix 0.5 | tee -a log_2.6G.txt
# python -m torch.distributed.run --nproc_per_node=8 main.py --epochs 300 --batch_size 128 --lr 2.0e-3 --model_ema true --model_ema_eval true --use_amp true --data_path /dev/shm/imagenet --output_dir ./checkpoint_4.3G --model large --mixup 0.8 --cutmix 1.0 | tee -a log_4.3G.txt
